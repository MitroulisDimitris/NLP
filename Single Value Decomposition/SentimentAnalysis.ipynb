{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://lazyprogrammer.me/course_files/AirlineTweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5 # confidence in sentiment threshold \n",
    "\n",
    "def process_string(s):\n",
    "    # Split the string on spaces\n",
    "    words = s.split()\n",
    "    \n",
    "    # Remove first element\n",
    "    words.pop(0)\n",
    "    \n",
    "    # Rejoin the list into a string\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "df = pd.read_csv('AirlineTweets.csv',delimiter=\",\")\n",
    "df = df[df['airline_sentiment_confidence']>threshold]\n",
    "df = df[['airline_sentiment','text']]\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "df['text'] = df['text'].apply(process_string)\n",
    "\n",
    "sentiment = df[\"airline_sentiment\"]\n",
    "text = df[\"text\"]\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "print(f\"Number of samples: {len(df)}\")\n",
    "\n",
    "## Convert classes to numbers\n",
    "#target_map = {\"pos\":1,\"neg\":0,\"neut\":2}\n",
    "#df['airline_sentiment'] = df['airline_sentiment'].map(target_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: create a function that splits the data but keeps the same percentage of each class in both train and test\n",
    "# Check for class imbalance\n",
    "\n",
    "test_plots = df['airline_sentiment'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### MIGHT BE WORKING BUT MY BRAIN IS FRYED RN,\n",
    "#### DONT RUN THIS FOR NOW :)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, sentiment, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase=True)\n",
    "\n",
    "# function .fit_transform() trains on a new vocabulary, \n",
    "# while .transform() trains on existing vocabulary\n",
    "X_train_vect = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_vect = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "\n",
    "Z_train = svd.fit_transform(X_train_vect.T)\n",
    "Z_test = svd.transform(X_test_vect.T)\n",
    "\n",
    "print(Z_train.shape)\n",
    "print(Z_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text, sentiment, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase=True)\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "\n",
    "# Create a pipeline that combines TfidfVectorizer and TruncatedSVD\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('svd', svd)\n",
    "])\n",
    "\n",
    "# Fit and transform the training data\n",
    "Z_train_svd = pipeline.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "Z_test_svd = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Z_train_svd.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000,class_weight='balanced')\n",
    "model.fit(Z_train_svd, y_train)\n",
    "print(\"Model train acc:\",model.score(Z_train_svd,y_train))\n",
    "print(\"Model test acc:\",model.score(Z_test_svd,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_proba(Z_test_svd)\n",
    "probs = [\"negative\",\"neuteral\",\"positive\"]\n",
    "\n",
    "negative_sentiment = {}\n",
    "neuteral_sentiment = {}\n",
    "positive_sentiment = {}\n",
    "\n",
    "\n",
    "for i,pred in enumerate(preds):\n",
    "  \n",
    "    index = np.argmax(pred)\n",
    "    \n",
    "    if index == 0:\n",
    "        negative_sentiment[X_test.iloc[i]] = pred[index]\n",
    "    \n",
    "    if index == 1:\n",
    "        neuteral_sentiment[X_test.iloc[i]] = pred[index]\n",
    "    \n",
    "    if index == 2:\n",
    "        positive_sentiment[X_test.iloc[i]] = pred[index]\n",
    "    \n",
    "        \n",
    "# get most positive review\n",
    "max_key = max(positive_sentiment, key=positive_sentiment.get)\n",
    "print(max_key)\n",
    "print(positive_sentiment[max_key])\n",
    "\n",
    "\n",
    "# get most negative review\n",
    "max_key = max(negative_sentiment, key=negative_sentiment.get)\n",
    "print(max_key)\n",
    "print(negative_sentiment[max_key])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample custom text for prediction\n",
    "custom_text = [\"it was mid\", \"it was awesome\",\"worst ever\"]\n",
    "\n",
    "# Transform the custom text using the same vectorizer\n",
    "custom_text_vectorized = pipeline.transform(custom_text)\n",
    "\n",
    "# Make the prediction\n",
    "predictions = model.predict(custom_text_vectorized)\n",
    "\n",
    "# Display the predictions\n",
    "for text, prediction in zip(custom_text, predictions):\n",
    "    print(f\"Text: {text}\\nPrediction: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate AUC Score\n",
    "P_train = model.predict_proba(Z_train_svd)\n",
    "P_test = model.predict_proba(Z_test_svd)\n",
    "print(\"Train AUC:\",roc_auc_score(y_train,P_train,multi_class='ovo'))\n",
    "print(\"Test AUC:\",roc_auc_score(y_test,P_test,multi_class='ovo'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,P_test,normalize='true')\n",
    "\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=probs, yticklabels=probs)\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
