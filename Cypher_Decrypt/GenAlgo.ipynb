{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://lazyprogrammer.me/course_files/moby_dick.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def has_duplicates(array):\n",
    "    return len(array) != len(set(array))\n",
    "\n",
    "def format_text(text):    \n",
    "    # Remove punctuation and digits\n",
    "    formatted_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    # remove more than one space in a row\n",
    "    formatted_text = re.sub(r'\\s{2,}', ' ', formatted_text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    formatted_text = formatted_text.lower()\n",
    "    # Remove spaces\n",
    "    #formatted_text = upper_text.replace(' ', '')\n",
    "    \n",
    "    return formatted_text\n",
    "\n",
    "\n",
    "def decode(array,dict):\n",
    "    #array = format_text(array)\n",
    "    decoded = []\n",
    "    for x in array:\n",
    "        try:\n",
    "            decoded.append(dict[x])\n",
    "        except:\n",
    "            decoded.append(\" \")\n",
    "    \n",
    "    return decoded\n",
    "\n",
    "def encode(text,cypher):\n",
    "    text = format_text(text)\n",
    "    \n",
    "    encoded = []\n",
    "    for x in text:\n",
    "        try:\n",
    "            encoded.append(cypher[x])\n",
    "        except:\n",
    "            encoded.append(\" \")\n",
    "        \n",
    "    return encoded\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize markov model\n",
    "M = np.ones((26,26))\n",
    "\n",
    "# initial state distribution\n",
    "pi = np.zeros(26)\n",
    "\n",
    "# function to update Markov model\n",
    "def update_M(char1, char2 ):\n",
    "    # convert letters to ascii to place them \n",
    "    # in the correct place in the Matrix M\n",
    "    # 'A' = 97 , 'B' = 98 ...\n",
    "    i = ord(char1) - 97\n",
    "    j = ord(char2) - 97\n",
    "    M[i,j] +=1\n",
    "    \n",
    "def update_init_distr(char1):\n",
    "    i = ord(char1) - 97\n",
    "    if i > 26:\n",
    "        print(i)\n",
    "    pi[i] += 1\n",
    "    \n",
    "def get_log_prob(word):\n",
    "    i = ord(word[0]) - 97\n",
    "    if i < 0:\n",
    "        return 0\n",
    "    logp = np.log(pi[i])\n",
    "    \n",
    "    for ch in word[1:]:\n",
    "        j = ord(ch) - 97\n",
    "        logp += np.log(M[i,j])\n",
    "       \n",
    "        i = j\n",
    "    \n",
    "    return logp\n",
    "\n",
    "# get probability of a sequence of words\n",
    "def get_sentence_log_prob(text):\n",
    "    if type(text) == str:\n",
    "        text = text.split()\n",
    "        \n",
    "    logp = 0\n",
    "    for word in text:\n",
    "        logp += get_log_prob(word)\n",
    "    \n",
    "    return logp\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "for line in open('moby_dick.txt' , encoding='utf-8'):\n",
    "    line = line.rstrip()\n",
    "    \n",
    "    if line:\n",
    "        line = format_text(line)\n",
    "        \n",
    "        tokens = line.split()\n",
    "        \n",
    "        for token in tokens:\n",
    "            ch0 = token[0]\n",
    "            update_init_distr(ch0)\n",
    "            \n",
    "            for ch1 in token[1:]:\n",
    "                update_M(ch0,ch1)\n",
    "                ch0 = ch1\n",
    "    \n",
    "    pi /= pi.sum()\n",
    "    M /= M.sum(axis=1,keepdims=True)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# implement evolutionary algorithm to decode the message\n",
    "alphabet = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "alphabet = [x.lower() for x in alphabet]\n",
    "\n",
    "\n",
    "enc_cypher = alphabet[:]\n",
    "random.seed(1234)\n",
    "random.shuffle(enc_cypher)\n",
    "\n",
    "enc_dict = dict(zip(alphabet, enc_cypher))\n",
    "\n",
    "\n",
    "message = \"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\"\n",
    "\n",
    "enc_message = encode(message,enc_dict)\n",
    "\n",
    "dna_pool = []\n",
    "for i in range(20):\n",
    "    dna = alphabet[:]\n",
    "    random.shuffle(dna)\n",
    "    dna_pool.append(dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_offspring(dna_pool,n_children):\n",
    "    # make n children for each offspring\n",
    "    offspring = []\n",
    "    \n",
    "    for dna in dna_pool:    \n",
    "        for _ in range(n_children):\n",
    "            copy = dna.copy()\n",
    "            # make random swaps \n",
    "            j,k = random.sample(range(len(copy)),2)\n",
    "            copy[j], copy[k] = copy[k],copy[j]\n",
    "             \n",
    "            offspring.append(copy)\n",
    "    \n",
    "    return offspring + dna_pool\n",
    "\n",
    "\n",
    "num_iters = 1000\n",
    "scores = np.zeros(num_iters)\n",
    "best_dna = None\n",
    "best_map = None\n",
    "best_score = float('-inf')\n",
    "\n",
    "for i in range(num_iters):\n",
    "    if i>0:\n",
    "        dna_pool = evolve_offspring(dna_pool,3)\n",
    "        \n",
    "    dna2score = {}\n",
    "    for dna in dna_pool:\n",
    "        current_map = {}\n",
    "        for k,v in zip(alphabet,dna):\n",
    "            current_map[k] = v\n",
    "        \n",
    "        decoded_message = decode(enc_message,current_map)\n",
    "        score  = get_sentence_log_prob(decoded_message)\n",
    "        \n",
    "        dna2score[''.join(dna)] = score\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_dna = dna\n",
    "            best_map = current_map\n",
    "            best_score = score\n",
    "            \n",
    "    scores[i] = np.mean(list(dna2score.values()))\n",
    "    \n",
    "    # keep 5 best dna\n",
    "    sorted_dna = sorted(dna2score.items(),key= lambda x:x[1], reverse= True)\n",
    "    dna_pool = [list(k) for k,v in sorted_dna[:5]]\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(\"iter:\", i , \"score:\", scores[i], \"best so far\", best_score)        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
