{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Text rank to preform text summarization\n",
    "\n",
    "- Text rank based summarization is essentially the same as Vector based but with a different ranking algorithm\n",
    "\n",
    "- **Text rank** is based on google's **Page rank** algorithm used to rank a webpage's poluparity.\n",
    "\n",
    "#### Steps\n",
    "1. Split the document into sentences\n",
    "2. Compute tf idf score for each sentence\n",
    "3. Compute cosine similarity between each sentence\n",
    "4. Sort by score \n",
    "5. Print N top, N% top, >N top sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dimitris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dimitris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "df = pd.read_csv('bbc_text_cls.csv')\n",
    "\n",
    "# helper function to remove newline\n",
    "def strip_nl(s):\n",
    "    return s.replace(\"\\n\",\" \")\n",
    "\n",
    "# remove newline\n",
    "df['text'] = df['text'].apply(strip_nl)\n",
    "\n",
    "# get random article\n",
    "article = df['text'].iloc[random.randint(0,len(df['text'])-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Split the document in sentences\n",
    "sentences = nltk.sent_tokenize(article)\n",
    "\n",
    "# calculate TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'),norm='l1')\n",
    "tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "\n",
    "#compute cosine similarity between each sentence\n",
    "# res is a tfidf[0] * tfidf[0] matrix\n",
    "S = cosine_similarity(tfidf_matrix)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences) == len(S[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize similarity matrix\n",
    "S /= S.sum(axis = 1, keepdims=True)\n",
    "S[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uniform transition matrix\n",
    "U = np.ones_like(S)/len(S)\n",
    "# Smoothed similarity matrix\n",
    "factor = 0.15\n",
    "S = (1-factor) *S +factor * U\n",
    "\n",
    "S[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.21907674, 0.7225    , 0.68056288, 0.28483241,\n",
       "       0.62196215, 0.60569211, 0.34382012, 0.3505369 , 0.36377105,\n",
       "       0.56879925, 0.40248621, 0.538296  , 0.43750048, 0.46529162,\n",
       "       0.49965687, 0.48755798])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find limting/ stationary distribution\n",
    "eigenvals, eigenvecs = np.linalg.eig(S.T)\n",
    "eigenvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32586662, -0.24131864, -0.23087772, -0.22113222, -0.25114315,\n",
       "       -0.2279602 , -0.2218763 , -0.25083325, -0.24869245, -0.21984717,\n",
       "       -0.23612786, -0.21835121, -0.25630691, -0.23618841, -0.23064255,\n",
       "       -0.2335762 , -0.25167594])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eigen vects are stored in columns\n",
    "eigenvecs[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32586662, -0.24131864, -0.23087772, -0.22113222, -0.25114315,\n",
       "       -0.2279602 , -0.2218763 , -0.25083325, -0.24869245, -0.21984717,\n",
       "       -0.23612786, -0.21835121, -0.25630691, -0.23618841, -0.23064255,\n",
       "       -0.2335762 , -0.25167594])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvecs[:,0].dot(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07943284, 0.05882353, 0.05627847, 0.05390291, 0.06121834,\n",
       "       0.05556729, 0.05408429, 0.0611428 , 0.06062096, 0.05358967,\n",
       "       0.05755823, 0.05322502, 0.06247705, 0.05757299, 0.05622114,\n",
       "       0.05693624, 0.06134821])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvecs[:,0] /eigenvecs[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "limiting_dist = np.ones(len(S)) / len(S)\n",
    "threshold = 1e-8\n",
    "delta = float('inf')\n",
    "iters = 0\n",
    "\n",
    "while delta> threshold:\n",
    "    iters +=1 \n",
    "    \n",
    "    #Markov_transition\n",
    "    p = limiting_dist.dot(S)\n",
    "    \n",
    "    # compute change in dist\n",
    "    delta = np.abs(p-limiting_dist).sum()\n",
    "    \n",
    "    # update limiting dist\n",
    "    limiting_dist = p\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07943284, 0.05882353, 0.05627847, 0.05390291, 0.06121834,\n",
       "       0.0555673 , 0.05408429, 0.0611428 , 0.06062096, 0.05358967,\n",
       "       0.05755823, 0.05322502, 0.06247705, 0.05757299, 0.05622114,\n",
       "       0.05693624, 0.06134821])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limiting_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999986"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limiting_dist.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4747766015343888e-08"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(eigenvecs[:,0] / eigenvecs[:,0].sum() - limiting_dist).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = limiting_dist\n",
    "sort_idx = np.argsort(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0794328417788865 Immigration to be election issue  Immigration and asylum have normally been issues politicians from the big parties have tiptoed around at election time.\n",
      "0.06247705245183829 But, while all the parties appear to agree the time has come to properly debate and address the issue, there are already signs they will run into precisely the same problems as before.\n",
      "0.06134821345017068 The challenge for the big parties is to ensure they can engage in the debate during the cut and thrust of a general election while also avoiding that trap.\n",
      "0.06121833970252338 That was also true at the last general election and the issue did briefly become a campaigning issue.\n",
      "0.06114279958487467 The Tories are already committed to imposing annual limits on immigration, with a quota for asylum seekers and with applications processed outside the UK.\n"
     ]
    }
   ],
   "source": [
    "# pick top N sentences\n",
    "\n",
    "N = 5\n",
    "for i in sort_idx[:N]:\n",
    "    print(f\"{scores[i]} {sentences[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
