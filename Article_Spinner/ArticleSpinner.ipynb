{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulding an article spinner\n",
    "\n",
    "1. Problem: How to replace enough words on a article so that it's different enough from the original and still makes sense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For article spinning:\n",
    "\n",
    "We need to predict the middle word\n",
    "\n",
    "p(wt | wt-1, wt+1) =   \n",
    "count(wt-1 -> wt -> wt+1) /   \n",
    "count(wt-1 -> ANY -> wt+1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-07-14 17:13:27--  https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv\n",
      "Resolving lazyprogrammer.me (lazyprogrammer.me)... 104.21.23.210, 172.67.213.166\n",
      "Connecting to lazyprogrammer.me (lazyprogrammer.me)|104.21.23.210|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5085081 (4,8M) [text/csv]\n",
      "Saving to: 'bbc_text_cls.csv'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1%  595K 8s\n",
      "    50K .......... .......... .......... .......... ..........  2% 99,2K 29s\n",
      "   100K .......... .......... .......... .......... ..........  3%  215K 26s\n",
      "   150K .......... .......... .......... .......... ..........  4% 92,7K 32s\n",
      "   200K .......... .......... .......... .......... ..........  5% 1,16M 26s\n",
      "   250K .......... .......... .......... .......... ..........  6%  402K 24s\n",
      "   300K .......... .......... .......... .......... ..........  7%  198K 23s\n",
      "   350K .......... .......... .......... .......... ..........  8%  172K 24s\n",
      "   400K .......... .......... .......... .......... ..........  9%  283K 23s\n",
      "   450K .......... .......... .......... .......... .......... 10%  233K 22s\n",
      "   500K .......... .......... .......... .......... .......... 11%  139K 23s\n",
      "   550K .......... .......... .......... .......... .......... 12%  305K 22s\n",
      "   600K .......... .......... .......... .......... .......... 13%  122K 23s\n",
      "   650K .......... .......... .......... .......... .......... 14%  401K 21s\n",
      "   700K .......... .......... .......... .......... .......... 15% 77,9K 23s\n",
      "   750K .......... .......... .......... .......... .......... 16% 38,0K 29s\n",
      "   800K .......... .......... .......... .......... .......... 17%  110M 27s\n",
      "   850K .......... .......... .......... .......... .......... 18% 12,5K 43s\n",
      "   900K .......... .......... .......... .......... .......... 19%  157K 41s\n",
      "   950K .......... .......... .......... .......... .......... 20%  154K 40s\n",
      "  1000K .......... .......... .......... .......... .......... 21%  102K 40s\n",
      "  1050K .......... .......... .......... .......... .......... 22%  740K 38s\n",
      "  1100K .......... .......... .......... .......... .......... 23%  297K 36s\n",
      "  1150K .......... .......... .......... .......... .......... 24% 79,6K 36s\n",
      "  1200K .......... .......... .......... .......... .......... 25%  173M 34s\n",
      "  1250K .......... .......... .......... .......... .......... 26%  435K 33s\n",
      "  1300K .......... .......... .......... .......... .......... 27%  104K 32s\n",
      "  1350K .......... .......... .......... .......... .......... 28%  169M 31s\n",
      "  1400K .......... .......... .......... .......... .......... 29%  161M 29s\n",
      "  1450K .......... .......... .......... .......... .......... 30%  336K 28s\n",
      "  1500K .......... .......... .......... .......... .......... 31% 65,4K 29s\n",
      "  1550K .......... .......... .......... .......... .......... 32% 79,8M 27s\n",
      "  1600K .......... .......... .......... .......... .......... 33%  306K 26s\n",
      "  1650K .......... .......... .......... .......... .......... 34%  117K 26s\n",
      "  1700K .......... .......... .......... .......... .......... 35%  168M 25s\n",
      "  1750K .......... .......... .......... .......... .......... 36% 1,07M 24s\n",
      "  1800K .......... .......... .......... .......... .......... 37%  540K 23s\n",
      "  1850K .......... .......... .......... .......... .......... 38%  553K 22s\n",
      "  1900K .......... .......... .......... .......... .......... 39%  529K 22s\n",
      "  1950K .......... .......... .......... .......... .......... 40%  105K 21s\n",
      "  2000K .......... .......... .......... .......... .......... 41% 67,1M 20s\n",
      "  2050K .......... .......... .......... .......... .......... 42% 60,6M 20s\n",
      "  2100K .......... .......... .......... .......... .......... 43%  486K 19s\n",
      "  2150K .......... .......... .......... .......... .......... 44% 79,0K 19s\n",
      "  2200K .......... .......... .......... .......... .......... 45% 90,9M 18s\n",
      "  2250K .......... .......... .......... .......... .......... 46%  185M 18s\n",
      "  2300K .......... .......... .......... .......... .......... 47%  272K 17s\n",
      "  2350K .......... .......... .......... .......... .......... 48% 70,1K 17s\n",
      "  2400K .......... .......... .......... .......... .......... 49% 94,8M 16s\n",
      "  2450K .......... .......... .......... .......... .......... 50% 28,8M 16s\n",
      "  2500K .......... .......... .......... .......... .......... 51%  534K 15s\n",
      "  2550K .......... .......... .......... .......... .......... 52% 60,2K 15s\n",
      "  2600K .......... .......... .......... .......... .......... 53%  155M 15s\n",
      "  2650K .......... .......... .......... .......... .......... 54% 19,7M 14s\n",
      "  2700K .......... .......... .......... .......... .......... 55%  176M 14s\n",
      "  2750K .......... .......... .......... .......... .......... 56%  245K 13s\n",
      "  2800K .......... .......... .......... .......... .......... 57%  532K 13s\n",
      "  2850K .......... .......... .......... .......... .......... 58%  115K 13s\n",
      "  2900K .......... .......... .......... .......... .......... 59%  179M 12s\n",
      "  2950K .......... .......... .......... .......... .......... 60% 94,8M 12s\n",
      "  3000K .......... .......... .......... .......... .......... 61%  418K 11s\n",
      "  3050K .......... .......... .......... .......... .......... 62%  372K 11s\n",
      "  3100K .......... .......... .......... .......... .......... 63% 2,08M 10s\n",
      "  3150K .......... .......... .......... .......... .......... 64%  105K 10s\n",
      "  3200K .......... .......... .......... .......... .......... 65%  201M 10s\n",
      "  3250K .......... .......... .......... .......... .......... 66%  198M 9s\n",
      "  3300K .......... .......... .......... .......... .......... 67%  834K 9s\n",
      "  3350K .......... .......... .......... .......... .......... 68%  495K 9s\n",
      "  3400K .......... .......... .......... .......... .......... 69%  101K 8s\n",
      "  3450K .......... .......... .......... .......... .......... 70%  166M 8s\n",
      "  3500K .......... .......... .......... .......... .......... 71%  141M 8s\n",
      "  3550K .......... .......... .......... .......... .......... 72%  324K 7s\n",
      "  3600K .......... .......... .......... .......... .......... 73%  238K 7s\n",
      "  3650K .......... .......... .......... .......... .......... 74% 84,2K 7s\n",
      "  3700K .......... .......... .......... .......... .......... 75% 36,8M 7s\n",
      "  3750K .......... .......... .......... .......... .......... 76%  109M 6s\n",
      "  3800K .......... .......... .......... .......... .......... 77%  148M 6s\n",
      "  3850K .......... .......... .......... .......... .......... 78%  321K 6s\n",
      "  3900K .......... .......... .......... .......... .......... 79%  332K 5s\n",
      "  3950K .......... .......... .......... .......... .......... 80% 46,1K 5s\n",
      "  4000K .......... .......... .......... .......... .......... 81%  118M 5s\n",
      "  4050K .......... .......... .......... .......... .......... 82%  754K 5s\n",
      "  4100K .......... .......... .......... .......... .......... 83%  149M 4s\n",
      "  4150K .......... .......... .......... .......... .......... 84%  753K 4s\n",
      "  4200K .......... .......... .......... .......... .......... 85% 58,3K 4s\n",
      "  4250K .......... .......... .......... .......... .......... 86%  196M 3s\n",
      "  4300K .......... .......... .......... .......... .......... 87%  170M 3s\n",
      "  4350K .......... .......... .......... .......... .......... 88% 4,39M 3s\n",
      "  4400K .......... .......... .......... .......... .......... 89%  405K 3s\n",
      "  4450K .......... .......... .......... .......... .......... 90% 74,0K 2s\n",
      "  4500K .......... .......... .......... .......... .......... 91%  144M 2s\n",
      "  4550K .......... .......... .......... .......... .......... 92%  138M 2s\n",
      "  4600K .......... .......... .......... .......... .......... 93% 9,03M 2s\n",
      "  4650K .......... .......... .......... .......... .......... 94%  535K 1s\n",
      "  4700K .......... .......... .......... .......... .......... 95%  454K 1s\n",
      "  4750K .......... .......... .......... .......... .......... 96% 65,1K 1s\n",
      "  4800K .......... .......... .......... .......... .......... 97%  100M 1s\n",
      "  4850K .......... .......... .......... .......... .......... 98%  185M 0s\n",
      "  4900K .......... .......... .......... .......... .......... 99%  165M 0s\n",
      "  4950K .......... .....                                      100%  130M=24s\n",
      "\n",
      "2024-07-14 17:13:52 (205 KB/s) - 'bbc_text_cls.csv' saved [5085081/5085081]\n",
      "\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dimitris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget -nc https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: have variable context size, 1,2, etc, \n",
    "# min acceptable prob to chnage a word\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textwrap\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business', 'politics', 'entertainment', 'sport', 'tech'}\n",
      "896    Labour plans maternity pay rise\\n\\nMaternity p...\n",
      "897    Watchdog probes e-mail deletions\\n\\nThe inform...\n",
      "898    Hewitt decries 'career sexism'\\n\\nPlans to ext...\n",
      "899    Labour chooses Manchester\\n\\nThe Labour Party ...\n",
      "900    Brown ally rejects Budget spree\\n\\nChancellor ...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv('bbc_text_cls.csv')#, on_bad_lines='skip')\n",
    "df.head()\n",
    "\n",
    "labels = set(df['labels'])\n",
    "print(labels)\n",
    "\n",
    "# train only from chosen labels\n",
    "label = 'politics'\n",
    "\n",
    "texts = df[df['labels'] == label]['text']\n",
    "print(texts.head()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Labour', 'maternity')\n",
      "Labour\n",
      "plans\n",
      "maternity\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('Labour', 'maternity'): {'plans': 1}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect counts\n",
    "\n",
    "probs = {} # key: [(wt-1), (wt+1)] value: [ wt / count(wt)]\n",
    "\n",
    "for doc in texts:\n",
    "    lines = doc.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        tokens = word_tokenize(line)\n",
    "        for i in range(len(tokens)-2):\n",
    "            t_0 = tokens[i]\n",
    "            t_1 = tokens[i+1]\n",
    "            t_2 = tokens[i+2]\n",
    "            key = (t_0, t_2)\n",
    "            print(key)\n",
    "            if key not in probs:\n",
    "                probs[key] = {}\n",
    "                \n",
    "            print(t_0)\n",
    "            print(t_1)\n",
    "            print(t_2)\n",
    "            # add count for middle token\n",
    "            if t_1 not in probs[key]:\n",
    "                probs[key][t_1] = 1\n",
    "            else: \n",
    "                probs[key][t_1] += 1\n",
    "            break\n",
    "        break\n",
    "    break\n",
    "probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize propabilities\n",
    "for key, d in probs.items():\n",
    "# d should represent a distibution\n",
    "    total = sum(d.values())\n",
    "    # access the dictionary of dictionaries, in corresponding key\n",
    "    # devide curernt count with total\n",
    "    for k, v in d.items():\n",
    "        d[k] = v/total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Labour plans maternity pay rise',\n",
       " '',\n",
       " 'Maternity pay for new mothers is to rise by £1,400 as part of new proposals announced by the Trade and Industry Secretary Patricia Hewitt.',\n",
       " '',\n",
       " 'It would mean paid leave would be increased to nine months by 2007, Ms Hewitt told GMTV\\'s Sunday programme. Other plans include letting maternity pay be given to fathers and extending rights to parents of older children. The Tories dismissed the maternity pay plan as \"desperate\", while the Liberal Democrats said it was misdirected.',\n",
       " '',\n",
       " 'Ms Hewitt said: \"We have already doubled the length of maternity pay, it was 13 weeks when we were elected, we have already taken it up to 26 weeks. \"We are going to extend the pay to nine months by 2007 and the aim is to get it right up to the full 12 months by the end of the next Parliament.\" She said new mothers were already entitled to 12 months leave, but that many women could not take it as only six of those months were paid. \"We have made a firm commitment. We will definitely extend the maternity pay, from the six months where it now is to nine months, that\\'s the extra £1,400.\" She said ministers would consult on other proposals that could see fathers being allowed to take some of their partner\\'s maternity pay or leave period, or extending the rights of flexible working to carers or parents of older children. The Shadow Secretary of State for the Family, Theresa May, said: \"These plans were announced by Gordon Brown in his pre-budget review in December and Tony Blair is now recycling it in his desperate bid to win back women voters.\"',\n",
       " '',\n",
       " 'She said the Conservatives would announce their proposals closer to the General Election. Liberal Democrat spokeswoman for women Sandra Gidley said: \"While mothers would welcome any extra maternity pay the Liberal Democrats feel this money is being misdirected.\" She said her party would boost maternity pay in the first six months to allow more women to stay at home in that time.',\n",
       " '',\n",
       " 'Ms Hewitt also stressed the plans would be paid for by taxpayers, not employers. But David Frost, director general of the British Chambers of Commerce, warned that many small firms could be \"crippled\" by the move. \"While the majority of any salary costs may be covered by the government\\'s statutory pay, recruitment costs, advertising costs, retraining costs and the strain on the company will not be,\" he said. Further details of the government\\'s plans will be outlined on Monday. New mothers are currently entitled to 90% of average earnings for the first six weeks after giving birth, followed by £102.80 a week until the baby is six months old.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text is split on paragraphs\n",
    "texts.iloc[0].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spin_document(doc):\n",
    "    # split document into lines\n",
    "    lines = doc.split(\"\\n\")\n",
    "    output = []\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            new_line = spin_line(line)\n",
    "        else:\n",
    "            new_line = line\n",
    "        output.append(new_line)\n",
    "        \n",
    "    return \"\\n\".join(output)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Maternity pay for new mothers is to rise by £1,400 as part of new proposals announced by the Trade and Industry Secretary Patricia Hewitt.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detokenizer = TreebankWordDetokenizer()\n",
    "texts.iloc[0].split(\"\\n\")[2]\n",
    "detokenizer.detokenize(word_tokenize(texts.iloc[0].split(\"\\n\")[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_word(d):\n",
    "    p0 = np.random.random()\n",
    "    cumulative = 0\n",
    "    for t,p in d.items():\n",
    "        cumulative += p\n",
    "        if p0 < cumulative:\n",
    "            return t\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spin_line(line):\n",
    "    tokens = word_tokenize(line)\n",
    "    i = 0\n",
    "    output = [tokens[0]]\n",
    "    \n",
    "\n",
    "    while i <(len(tokens)-2):\n",
    "        t_0 = tokens[i]\n",
    "        t_1 = tokens[i+1]\n",
    "        t_2 = tokens[i+2]\n",
    "        key = (t_0, t_2)\n",
    "        \n",
    "        try:\n",
    "            p_dist = probs[key]\n",
    "        except:\n",
    "            print(\"hello\")\n",
    "        if len(p_dist) > 1 and np.random.random() < 0.3:\n",
    "            # replace middle word\n",
    "            middle = sample_word(p_dist)\n",
    "            output.append(t_1)\n",
    "            output.append(\"<\"+middle+\">\")\n",
    "            output.append(t_2)\n",
    "            \n",
    "            # skip 2 steps \n",
    "            i +=2\n",
    "        \n",
    "        else:\n",
    "            # dont replace middle word\n",
    "            output.append(t_1)\n",
    "            i+=1\n",
    "        \n",
    "        \n",
    "    # append the final token\n",
    "    if i == (len(tokens)-2):\n",
    "        output.append(tokens[-1])\n",
    "    return detokenizer.detokenize(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKIP outspent Labour on EU poll\n",
      "\n",
      "The UK Independence Party outspent\n",
      "both Labour and the Liberal Democrats in the European <European>\n",
      "elections, new figures show <\">.\n",
      "\n",
      "UKIP, which campaigned <campaigned>\n",
      "on a slogan of \"Say <can> no to Europe\" <has>, spent £2.36m <yearly>\n",
      "on the campaign - second only <place> to the Conservatives' £3.13m .\n",
      "The campaign took UKIP into third place with an extra 10 MEPs . Labour\n",
      "<Australia>'s campaign cost £1.7m, the Lib Dems' £1.19m and the\n",
      "Greens' £404,000, according to figures revealed <revealed> by the\n",
      "Electoral Commission on Wednesday . Much of the UKIP funding came from\n",
      "Yorkshire millionaire Sir Paul Sykes <Sykes>, who helped bankroll the\n",
      "party's billboard <billboard> campaign . Critics <I> have accused the\n",
      "party of effectively buying votes <votes>. But <Possibly> a UKIP\n",
      "spokesman said Labour and <explaining> the Conservatives had spent\n",
      "£10m between them on <attending> the last general election . \"With the\n",
      "advantages <end> of public <the> money the others have, the only way\n",
      "the smaller parties can get <ignore> their message across is by buying\n",
      "the advertising space,\" he added <said>.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "i = np.random.choice(texts.shape[0])\n",
    "doc = texts.iloc[i]\n",
    "new_doc = spin_document(doc)\n",
    "print(textwrap.fill(new_doc, replace_whitespace=False,fix_sentence_endings=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
