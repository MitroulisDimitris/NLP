{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis Using linear regression\n",
    "1. Download and import dataset\n",
    "2. Clean, rename columns, check data\n",
    "3. Tokenize words\n",
    "4. Train model\n",
    "5. Check accuracy\n",
    "6. Run AUC, F1\n",
    " \n",
    " \n",
    "**Extras**\n",
    "- Build Binary classifier\n",
    "- Interpet results\n",
    "- Print words with the most positive and negative weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-07-31 18:58:04--  https://lazyprogrammer.me/course_files/AirlineTweets.csv\n",
      "Resolving lazyprogrammer.me (lazyprogrammer.me)... 172.67.213.166, 104.21.23.210\n",
      "Connecting to lazyprogrammer.me (lazyprogrammer.me)|172.67.213.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3421431 (3,3M) [text/csv]\n",
      "Saving to: 'AirlineTweets.csv'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1% 1,28M 3s\n",
      "    50K .......... .......... .......... .......... ..........  2%  602K 4s\n",
      "   100K .......... .......... .......... .......... ..........  4%  299K 6s\n",
      "   150K .......... .......... .......... .......... ..........  5% 77,7K 15s\n",
      "   200K .......... .......... .......... .......... ..........  7% 84,1M 12s\n",
      "   250K .......... .......... .......... .......... ..........  8% 24,1M 9s\n",
      "   300K .......... .......... .......... .......... .......... 10%  154M 8s\n",
      "   350K .......... .......... .......... .......... .......... 11%  406K 8s\n",
      "   400K .......... .......... .......... .......... .......... 13%  591K 7s\n",
      "   450K .......... .......... .......... .......... .......... 14%  532K 7s\n",
      "   500K .......... .......... .......... .......... .......... 16% 91,4K 9s\n",
      "   550K .......... .......... .......... .......... .......... 17% 84,4M 8s\n",
      "   600K .......... .......... .......... .......... .......... 19%  135M 7s\n",
      "   650K .......... .......... .......... .......... .......... 20% 1,28M 7s\n",
      "   700K .......... .......... .......... .......... .......... 22% 1,42M 6s\n",
      "   750K .......... .......... .......... .......... .......... 23%  479K 6s\n",
      "   800K .......... .......... .......... .......... .......... 25% 2,19M 6s\n",
      "   850K .......... .......... .......... .......... .......... 26%  895K 6s\n",
      "   900K .......... .......... .......... .......... .......... 28%  333K 6s\n",
      "   950K .......... .......... .......... .......... .......... 29%  214K 6s\n",
      "  1000K .......... .......... .......... .......... .......... 31% 47,9M 5s\n",
      "  1050K .......... .......... .......... .......... .......... 32% 24,2M 5s\n",
      "  1100K .......... .......... .......... .......... .......... 34%  498K 5s\n",
      "  1150K .......... .......... .......... .......... .......... 35%  143K 5s\n",
      "  1200K .......... .......... .......... .......... .......... 37%  108M 5s\n",
      "  1250K .......... .......... .......... .......... .......... 38%  485K 5s\n",
      "  1300K .......... .......... .......... .......... .......... 40%  745K 4s\n",
      "  1350K .......... .......... .......... .......... .......... 41%  499K 4s\n",
      "  1400K .......... .......... .......... .......... .......... 43%  779K 4s\n",
      "  1450K .......... .......... .......... .......... .......... 44% 1,73M 4s\n",
      "  1500K .......... .......... .......... .......... .......... 46% 1,30M 4s\n",
      "  1550K .......... .......... .......... .......... .......... 47%  110K 4s\n",
      "  1600K .......... .......... .......... .......... .......... 49% 63,2M 4s\n",
      "  1650K .......... .......... .......... .......... .......... 50%  116M 4s\n",
      "  1700K .......... .......... .......... .......... .......... 52%  998K 3s\n",
      "  1750K .......... .......... .......... .......... .......... 53% 1,30M 3s\n",
      "  1800K .......... .......... .......... .......... .......... 55%  786K 3s\n",
      "  1850K .......... .......... .......... .......... .......... 56%  713K 3s\n",
      "  1900K .......... .......... .......... .......... .......... 58%  567K 3s\n",
      "  1950K .......... .......... .......... .......... .......... 59%  697K 3s\n",
      "  2000K .......... .......... .......... .......... .......... 61% 2,03M 3s\n",
      "  2050K .......... .......... .......... .......... .......... 62% 2,55M 2s\n",
      "  2100K .......... .......... .......... .......... .......... 64% 1,56M 2s\n",
      "  2150K .......... .......... .......... .......... .......... 65% 1,45M 2s\n",
      "  2200K .......... .......... .......... .......... .......... 67% 2,16M 2s\n",
      "  2250K .......... .......... .......... .......... .......... 68% 1,05M 2s\n",
      "  2300K .......... .......... .......... .......... .......... 70% 3,02M 2s\n",
      "  2350K .......... .......... .......... .......... .......... 71% 1,67M 2s\n",
      "  2400K .......... .......... .......... .......... .......... 73% 2,05M 2s\n",
      "  2450K .......... .......... .......... .......... .......... 74% 1,42M 1s\n",
      "  2500K .......... .......... .......... .......... .......... 76% 2,28M 1s\n",
      "  2550K .......... .......... .......... .......... .......... 77% 1,33M 1s\n",
      "  2600K .......... .......... .......... .......... .......... 79% 2,37M 1s\n",
      "  2650K .......... .......... .......... .......... .......... 80% 2,52M 1s\n",
      "  2700K .......... .......... .......... .......... .......... 82% 1,25M 1s\n",
      "  2750K .......... .......... .......... .......... .......... 83%  675K 1s\n",
      "  2800K .......... .......... .......... .......... .......... 85% 2,98M 1s\n",
      "  2850K .......... .......... .......... .......... .......... 86% 1,73M 1s\n",
      "  2900K .......... .......... .......... .......... .......... 88%  288K 1s\n",
      "  2950K .......... .......... .......... .......... .......... 89% 23,6M 1s\n",
      "  3000K .......... .......... .......... .......... .......... 91% 2,07M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 92% 7,54M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 94% 4,98M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 95% 1,40M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 97% 1,43M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 98% 1,85M 0s\n",
      "  3300K .......... .......... .......... .......... .         100% 2,10M=5,0s\n",
      "\n",
      "2024-07-31 18:58:10 (670 KB/s) - 'AirlineTweets.csv' saved [3421431/3421431]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://lazyprogrammer.me/course_files/AirlineTweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 14404\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5 # confidence in sentiment threshold \n",
    "\n",
    "df = pd.read_csv('AirlineTweets.csv',delimiter=\",\")\n",
    "df = df[df['airline_sentiment_confidence']>threshold]\n",
    "df = df[['airline_sentiment','text']]\n",
    "\n",
    "sentiment = df[\"airline_sentiment\"]\n",
    "text = df[\"text\"]\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n",
    "print(f\"Number of samples: {len(df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
